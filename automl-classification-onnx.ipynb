{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# AutoML ONNX: Train \"the best\" classifier model for the Iris dataset.\n",
    "\n",
    "この Notebook では Open Neural Network Exchange (ONNX) を使用して、Azure Machine Learning の自動機械学習 (AutoML) から生成されたモデルで予測を行う方法について説明します。\n",
    "\n",
    "必要条件 - このチュートリアルの恩恵を受けるためには、以下のものが必要です：\n",
    "\n",
    "- 機械学習の基本的な理解\n",
    "- アクティブなサブスクリプションを持つAzureアカウント。[無料でアカウントを作成](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- Azure ML ワークスペース。ワークスペースの作成については、[このノートブック](https://github.com/Azure/azureml-examples/blob/013bff90530ac920909132ef0362049d63151a40/sdk/python/resources/workspace/workspace.ipynb)を参照してください。\n",
    "- コンピュートクラスタ。コンピュートクラスタを作成するには、[このノートブック](https://github.com/Azure/azureml-examples/blob/013bff90530ac920909132ef0362049d63151a40/sdk/python/resources/compute/compute.ipynb)を参照してください。\n",
    "- Python 環境\n",
    "- Azure Machine Learning Python SDK v2 をインストール - インストール手順 - [Getting started](https://github.com/Azure/azureml-examples/blob/013bff90530ac920909132ef0362049d63151a40/sdk/python/README.md) セクションを確認してください。<br>\n",
    "Azure Machine Learning Notebooks には既にインストールされています。右上から `Python 3.10 - SDK v2` カーネルを選択します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 1. Connect to Azure Machine Learning Workspace\n",
    "### Configure workspace details and get a handle to the workspace\n",
    "ワークスペースは、Azure Machine Learning の最上位リソースであり、Azure Machine Learning を使用するときに作成するすべての成果物で作業するための一元的な場所を提供します。このセクションでは、ジョブを実行するワークスペースに接続します。\n",
    "\n",
    "ワークスペースに接続するには、識別子パラメーター（サブスクリプション、リソースグループ、ワークスペース名）が必要です。`azure.ai.ml` の `MLClient` でこれらの詳細を使用して、必要な Azure Machine Learning ワークスペースへのハンドルを取得します。このチュートリアルでは、デフォルトの [Azure 認証](https://learn.microsoft.com/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python)を使用します。認証情報を設定してワークスペースに接続する方法の詳細については、[設定ノートブック](https://github.com/Azure/azureml-examples/blob/013bff90530ac920909132ef0362049d63151a40/sdk/python/jobs/configuration.ipynb)を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693004917112
    }
   },
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your Azure Machine Learning workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace = \"<AML_WORKSPACE_NAME>\"\n",
    "\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)\n",
    "\n",
    "print(ml_client.workspace_name, ml_client.connections._subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Show Azure ML Workspace information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693002257331
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "workspace = ml_client.workspaces.get(name=ml_client.workspace_name)\n",
    "\n",
    "subscription_id = ml_client.connections._subscription_id\n",
    "resource_group = workspace.resource_group\n",
    "workspace_name = ml_client.workspace_name\n",
    "\n",
    "output = {}\n",
    "output[\"Workspace\"] = workspace_name\n",
    "output[\"Subscription ID\"] = subscription_id\n",
    "output[\"Resource Group\"] = resource_group\n",
    "output[\"Location\"] = workspace.location\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MLTable with input Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Register training data\n",
    "省略。[sklearn.datasets.load_iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) を Machine Learning Studio UI から登録済み。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "registered_data_asset = ml_client.data.get(name='Iris-cleaned', version=\"1\")\n",
    "my_training_data_input = Input(\n",
    "    type=AssetTypes.MLTABLE, \n",
    "    path=registered_data_asset.id\n",
    ")\n",
    "\n",
    "my_training_data_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 3. Compute target setup\n",
    "\n",
    "### Use existing compute target or create new (Basic)\n",
    "\n",
    "Azure Machine Learning Computeは、適切な VM Family のシングルノードからマルチノードコンピュートまでを簡単に作成できるマネージドコンピュートインフラストラクチャです。**ワークスペース・リージョン内**に作成され、ワークスペース内の他のユーザーが使用できるリソースです。ジョブが投入されると、デフォルトで max_nodes までオートスケールされ、ユーザが指定した依存関係をパッケージングしたコンテナ化環境で実行されます。\n",
    "\n",
    "マネージドコンピュートなので、ジョブのスケジューリングとクラスタの管理は Azure Machine Learning サービスが内部で行う。\n",
    "\n",
    "コンピュートクラスタは `AmlCompute` クラスを使用して作成できる。このクラスの主要なパラメータは以下の通りである：\n",
    "\n",
    "* `size` - クラスタに使用する VM のサイズ。詳細については、[Supported VM series and sizes](https://docs.microsoft.com/azure/machine-learning/concept-compute-target#supported-vm-series-and-sizes) を参照してください。\n",
    "* `max_instances` - クラスタで使用するノードの最大数。デフォルトは 1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cluster_name = \"ClusterDS3\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cluster = ml_client.compute.get(cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except Exception:\n",
    "    compute = AmlCompute(name=cluster_name, size='STANDARD_DS3_V2',\n",
    "                         max_instances=4)\n",
    "    cluster = ml_client.compute.begin_create_or_update(compute)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Configure and run the AutoML classification job\n",
    "\n",
    "### classification() parameters:\n",
    "\n",
    "`classification()` ファクトリ関数を使うと、最も一般的なシナリオの分類タスク用に AutoML を設定することができます。\n",
    "\n",
    "- `target_column_name` - 予測の対象となるカラムの名前。常に指定する必要がある。このパラメータは 'training_data'、'validation_data'、'test_data' に適用できる。\n",
    "- `primary_metric` - 分類モデル選択のために AutoML が最適化する指標。\n",
    "- `training_data` - 学習に使用するデータ。トレーニング特徴列とターゲット列の両方を含む必要がある。オプションとして、このデータを分割して検証データセットやテストデータセットとすることもできる。\n",
    "ワークスペースに登録されている MLTable を '<mltable_name>:<version>' というフォーマットで使用するか、ローカルのファイルやフォルダを MLTable として使用することができます。例： Input(mltable='my_mltable:1') OR Input(mltable=MLTable(local_path=\"./data\"))\n",
    "パラメータ 'training_data' は必ず指定すること。\n",
    "- `compute` - AutoMLジョブが実行されるコンピュートターゲット。この例では、ワークスペースに存在する 'cpu-cluster' というコンピュートを使っています。ワークスペース内の他のコンピュートと置き換えることもできます。\n",
    "- `name` - ジョブ/ランの名前です。これはオプションのプロパティです。指定しない場合は、ランダムな名前が生成される。\n",
    "- `experiment_name` - 実験の名前。Experiment は、Azure ML Workspace 内にある、同じ論理的な機械学習実験に関連する複数の実行を含むフォルダのようなものです。\n",
    "\n",
    "\n",
    "### set_limits() function parameters:\n",
    "これはタイムアウトなどの制限パラメータを設定するためのオプションの設定方法です。    \n",
    "    \n",
    "- `timeout_minutes` - AutoML ジョブ全体が終了するまでの最大時間（分）。このタイムアウトには、セットアップ、特徴量化、トレーニングの実行は含まれるが、処理の最後に行われるアンサンブルとモデルの説明可能性の実行は含まれない。指定しない場合、デフォルトのジョブの合計タイムアウトは6日（8,640分）です。1時間（60分）以下のタイムアウトを指定するには、データセットのサイズが10,000,000（行×列）以下であることを確認してください。\n",
    "\n",
    "- `trial_timeout_minutes` - 各トライアル（子ジョブ）が終了するまでの最大時間（分）。指定しない場合は、1ヶ月または 43200 分の値が使用される。\n",
    "    \n",
    "- `max_trials` - 1つの AutoML ジョブで、アルゴリズムとハイパーパラメータの組み合わせを変えて試行/実行する回数の最大値。指定しない場合、デフォルトは 1000 試行である。enable_early_termination' を使用する場合は、試行回数を少なくすることができる。\n",
    "    \n",
    "- `max_concurrent_trials` - 並列実行されるトライアル（子ジョブ）の最大数を表す。この数とクラスタのノード数を一致させるのが良い方法である。\n",
    "    \n",
    "- `enable_early_termination` - スコアが短期的に向上しない場合に、早期終了を有効にするかどうか。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693004137626
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import automl, Input\n",
    "\n",
    "# note that this is a code snippet -- you might have to modify the variable values to run it successfully\n",
    "# configure the classification job\n",
    "classification_job = automl.classification(\n",
    "    compute='ClusterDS3',\n",
    "    experiment_name='IrisClassifySDK',\n",
    "    training_data=my_training_data_input,\n",
    "    target_column_name=\"Species\",\n",
    "    primary_metric=\"accuracy\",\n",
    "    n_cross_validations=5,\n",
    "    enable_model_explainability=True,\n",
    "    tags={\"my_custom_tag\": \"SDK v2\"}\n",
    ")\n",
    "\n",
    "# Limits are all optional\n",
    "classification_job.set_limits(\n",
    "    timeout_minutes=600, \n",
    "    trial_timeout_minutes=20, \n",
    "    max_trials=5,\n",
    "    enable_early_termination=True,\n",
    ")\n",
    "\n",
    "# Training properties are optional\n",
    "classification_job.set_training(\n",
    "    blocked_training_algorithms=[\"logistic_regression\"], \n",
    "    enable_onnx_compatible_models=True #ONNX 互換モデルの生成を有効にする\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 5. Run the Command\n",
    "先ほど作成した `MLClient` を使って、ワークスペースでこのコマンドを実行します。<br>\n",
    "Machine Learning Studio の ジョブに登録されていることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693004148066
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# submit the job to the backend\n",
    "returned_job = ml_client.jobs.create_or_update(classification_job)\n",
    "\n",
    "print(f\"Created job: {returned_job}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 6. Retrieve the Best Trial (Best Model's trial/run)\n",
    "MLFLowClient を使用して、以前に完了した AutoML トレーニングの結果（モデル、成果物、メトリクスなど）にアクセスします。<br>\n",
    "この作業は Machine Learning Studio UI から行うこともできます。\n",
    "\n",
    "\n",
    "### 6.1. Obtain the tracking URI for MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693004927678
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Obtain the tracking URL from MLClient\n",
    "MLFLOW_TRACKING_URI = ml_client.workspaces.get(\n",
    "    name=ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693004946736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Set the MLFLOW TRACKING URI\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693004948729
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking.client import MlflowClient\n",
    "from mlflow.artifacts import download_artifacts\n",
    "\n",
    "# Initialize MLFlow client\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 6.2. Get the AutoML parent Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693005033680
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_name = returned_job.name\n",
    "\n",
    "# Example if providing an specific Job name/ID\n",
    "# job_name = \"b4e95546-0aa1-448e-9ad6-002e3207b4fc\"\n",
    "\n",
    "# Get the parent run\n",
    "mlflow_parent_run = mlflow_client.get_run(job_name)\n",
    "\n",
    "print(\"Parent Run: \")\n",
    "print(mlflow_parent_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693005045754
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Print parent run tags. 'automl_best_child_run_id' tag should be there.\n",
    "print(mlflow_parent_run.data.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 6.3. Get the AutoML best child run\n",
    "親の Run を取得できたら最も精度の高い子 Run を取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693005050672
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get the best model's child run\n",
    "\n",
    "best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\n",
    "print(\"Found best child run id: \", best_child_run_id)\n",
    "\n",
    "best_run = mlflow_client.get_run(best_child_run_id)\n",
    "\n",
    "print(\"Best child run: \")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 6.4. Get best model run's metrics\n",
    "過去に実行したAutoMLの結果（モデル、成果物、メトリクスなど）にアクセスします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693005057750
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_run.data.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 6.5. Download the best model locally\n",
    "Machine Learning Studio の UI から直接ダウンロードもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693005071679
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create local folder\n",
    "local_dir = \"./artifact_downloads\"\n",
    "if not os.path.exists(local_dir):\n",
    "    os.mkdir(local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693005075850
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Download run's artifacts/outputs\n",
    "local_path = download_artifacts(\n",
    "    run_id=best_run.info.run_id, artifact_path=\"outputs\", dst_path=local_dir\n",
    ")\n",
    "print(\"Artifacts downloaded in: {}\".format(local_path))\n",
    "print(\"Artifacts: {}\".format(os.listdir(local_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693005084055
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Show the contents of the MLFlow model folder\n",
    "os.listdir(\"./artifact_downloads/outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 7. Predict models\n",
    "pkl 形式で保存したモデルと onnx 形式で保存したモデルで推論結果を比較します。\n",
    "\n",
    "### 7.1. load model using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693006640738
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model_path = './artifact_downloads/outputs/model.pkl'\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693006438779
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Train a model.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693006983031
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "#data_sample = PandasParameterType(pd.DataFrame({\"SepalLengthCm\": pd.Series([0.0], dtype=\"float64\"), \"SepalWidthCm\": pd.Series([0.0], dtype=\"float64\"), \"PetalLengthCm\": pd.Series([0.0], dtype=\"float64\"), \"PetalWidthCm\": pd.Series([0.0], dtype=\"float64\")}))\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "feature_names = [\n",
    "        'SepalLengthCm',\n",
    "        'SepalWidthCm',\n",
    "        'PetalLengthCm',\n",
    "        'PetalWidthCm']\n",
    "df = pd.DataFrame(iris.data, columns=feature_names)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693007046758
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model.predict(df[70:71])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 7.2. load model using onnx\n",
    "Open Neural Network Exchange (ONNX) を使用して、Azure Machine Learning の自動機械学習 (AutoML) から生成されたモデルで予測を行う方法について説明します。\n",
    "\n",
    "予測に ONNX を使用するには、次のことを行う必要があります。\n",
    "\n",
    "- AutoML トレーニングの実行から ONNX モデル ファイルをダウンロードします\n",
    "- ONNX モデルの入力と出力を理解します\n",
    "- 入力に必要な形式になるようにデータを前処理します\n",
    "- Python 用の ONNX ランタイムで推論を実行します\n",
    "\n",
    "\n",
    "ONNX Runtime は、クロスプラットフォームの推論をサポートするオープン ソース プロジェクトです。 ONNX ランタイムでは、複数のプログラミング言語 (Python、C++、C#、C、Java、JavaScript など) にわたって API が提供されます。 これらの API を使用して、入力データに対する推論を実行できます。 ONNX 形式でエクスポートされたモデルの作成後、プロジェクトに必要な任意のプログラミング言語でこれらの API を使用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#onnxruntime パッケージをインストールします。\n",
    "#%pip install onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードした ONNX モデル ファイル `model.onnx` をロードします。\n",
    "ロードしたら、ONNX モデルの入力と出力を理解します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prediction with ONNX Runtime\n",
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "\n",
    "sess = rt.InferenceSession(\"./artifact_downloads/outputs/model.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "print(input_name, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in sess.get_inputs():\n",
    "    print(ix.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONNX モデルで想定される入力形式に合わせます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = [5.9, 3.2, 4.8, 1.8]\n",
    "\n",
    "input_data = {\n",
    "    'SepalLengthCm': np.array([[input_values[0]]], dtype=np.float32),\n",
    "    'SepalWidthCm':  np.array([[input_values[1]]], dtype=np.float32),\n",
    "    'PetalLengthCm': np.array([[input_values[2]]], dtype=np.float32),\n",
    "    'PetalWidthCm':  np.array([[input_values[3]]], dtype=np.float32)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推論を実行します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_onx = sess.run([label_name], input_data)[0]\n",
    "pred_onx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
